# ============================================
# HR Command Center - Environment Configuration
# ============================================
# Copy this to .env.local for local development
# DO NOT commit .env.local to version control
#
# Quick Start:
# 1. Copy this file: cp .env.example .env.local
# 2. Fill in your API keys below
# 3. Start the app: npm run dev
#
# Documentation: See README.md and docs/guides/DEVELOPMENT_SETUP.md

# ================================
# Environment
# ================================
NODE_ENV=development
PORT=3000

# ================================
# Security Configuration
# ================================
# JWT Secret for authentication (minimum 32 characters)
# IMPORTANT: Change this in production!
JWT_SECRET=dev_secret_change_in_production_32_character_minimum_length_required

# CORS Configuration
ALLOWED_ORIGIN=http://localhost:3000

# ================================
# Claude AI Configuration
# ================================
# Get API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your_key_here

# ================================
# Rippling Configuration
# ================================
# Generate API key in Rippling settings
RIPPLING_API_KEY=rpl_your_key_here
RIPPLING_BASE_URL=https://api.rippling.com

# ================================
# Notion Configuration
# ================================
# Create integration at: https://www.notion.so/my-integrations
NOTION_TOKEN=secret_your_token_here
NOTION_VERSION=2022-06-28
NOTION_ONBOARDING_DB=your_database_id_here
NOTION_HR_PROJECTS_DB=your_database_id_here

# ================================
# Google Workspace Configuration
# ================================
# CURRENT IMPLEMENTATION: Service Account (Recommended)
# The existing code uses Service Account authentication via googleapis JWT
#
# Service Account Setup:
# 1. Create service account in Google Cloud Console
# 2. Enable APIs: Drive, Docs, Sheets, Gmail, Calendar
# 3. Download JSON key file
# 4. Share your Drive folders with the service account email
# 5. For domain-wide delegation (optional): enable in Workspace Admin
#
GOOGLE_CREDENTIALS_PATH=/path/to/service-account-key.json
GOOGLE_ADMIN_EMAIL=admin@yourcompany.com
GOOGLE_DOMAIN=yourcompany.com

# OAuth 2.0 Client Setup (Alternative - NOT currently implemented):
# Use this approach if you want end-user authentication via "Sign in with Google"
# GOOGLE_CLIENT_ID=your_client_id_here
# GOOGLE_CLIENT_SECRET=your_client_secret_here
# GOOGLE_REDIRECT_URI=http://localhost:3000/api/auth/callback/google

# ================================
# Slack Configuration
# ================================
# Create app at: https://api.slack.com/apps
# Add bot token scopes: chat:write, im:write, users:read
SLACK_BOT_TOKEN=xoxb-your_token_here
SLACK_SIGNING_SECRET=your_signing_secret_here
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/your/webhook/url
SLACK_WORKSPACE_ID=T...

# ================================
# Calendly Configuration
# ================================
# Generate API key in Calendly settings
CALENDLY_API_KEY=your_api_key_here
CALENDLY_WEBHOOK_SECRET=your_webhook_secret_here
CALENDLY_DEFAULT_USER_URI=https://api.calendly.com/users/your_user_id

# ================================
# Application Configuration
# ================================
NEXT_PUBLIC_APP_NAME=HR Command Center
NEXT_TELEMETRY_DISABLED=0

# ================================
# Database Configuration (future)
# ================================
DATABASE_URL=postgresql://hrskills_user:password@localhost:5432/hrskills_dev
REDIS_URL=redis://localhost:6379

# ================================
# Feature Flags
# ================================
ENABLE_DEBUG_LOGGING=true
ENABLE_ANALYTICS=false

# ============================================
# Google Cloud AI Services Configuration
# ============================================
# Documentation: See docs/guides/NLP_INTEGRATION_GUIDE.md
# Cost: $20-50/month total for all 6 AI services

# ============================================
# Google Cloud Credentials (Required for AI)
# ============================================
# Path to your Google Cloud service account JSON key file
# This is shared across all Google AI services (DLP, NLP, Translation, etc.)
# Same as GOOGLE_CREDENTIALS_PATH above if using same service account
GOOGLE_APPLICATION_CREDENTIALS=/path/to/your-service-account-key.json

# Google Cloud project ID (required for Document AI and Vertex AI)
GOOGLE_CLOUD_PROJECT=your-project-id

# ============================================
# Phase 1: Natural Language API
# ============================================
# Enable sentiment analysis, entity extraction, and content classification
# Cost: $5-8/month with caching enabled
# Free tier: First 5,000 records/month
NEXT_PUBLIC_ENABLE_NLP=true

# ============================================
# Phase 2: Translation API
# ============================================
# Enable automatic translation for multilingual support
# Cost: $0/month (stays within free tier)
# Free tier: 500,000 characters/month, then $20/1M characters
NEXT_PUBLIC_ENABLE_TRANSLATION=true

# ============================================
# Phase 3: Speech-to-Text API
# ============================================
# Enable audio transcription for interviews
# Cost: $15-25/month
# Free tier: 60 minutes/month, then $0.024/minute ($1.44/hour)
NEXT_PUBLIC_ENABLE_SPEECH=true

# ============================================
# Phase 4: Document AI
# ============================================
# Enable resume parsing, form extraction, and OCR
# Cost: $0-15/month
# Free tier: 1,000 pages/month, then $1.50-$10/1000 pages
NEXT_PUBLIC_ENABLE_DOCUMENT_AI=true

# Document AI location (default: us)
DOCUMENT_AI_LOCATION=us

# Processor IDs (create these in Google Cloud Console)
# Resume Parser Processor ID (specialized parser: $10/1000 pages)
DOCUMENT_AI_RESUME_PROCESSOR_ID=your-resume-processor-id

# Form Parser Processor ID (for W-4, I-9, etc.: $10/1000 pages)
DOCUMENT_AI_FORM_PROCESSOR_ID=your-form-processor-id

# OCR Processor ID (general OCR: $1.50/1000 pages)
DOCUMENT_AI_OCR_PROCESSOR_ID=your-ocr-processor-id

# ============================================
# Phase 5: Vertex AI
# ============================================
# Enable predictive analytics and ML models
# Cost: $0-1/month (rule-based predictions free, ML predictions $0.000002/prediction)
# Training cost (optional): $19.32/hour per model (one-time)
NEXT_PUBLIC_ENABLE_VERTEX_AI=true

# Vertex AI location (default: us-central1)
VERTEX_AI_LOCATION=us-central1

# ML Model Endpoint IDs (optional - create after training models)
# Leave blank to use rule-based predictions (70-75% accuracy)
# Set these after training AutoML models for 80-90% accuracy
VERTEX_AI_ATTRITION_ENDPOINT_ID=your-attrition-endpoint-id
VERTEX_AI_PERFORMANCE_ENDPOINT_ID=your-performance-endpoint-id
VERTEX_AI_PROMOTION_ENDPOINT_ID=your-promotion-endpoint-id

# ============================================
# Phase 6: Vision API
# ============================================
# Enable image analysis, ID verification, and content moderation
# Cost: $0-2/month
# Free tier: 1,000 units/month, then $1.50/1000 images
NEXT_PUBLIC_ENABLE_VISION=true

# Vision API features (all enabled by default):
# - Text detection (OCR)
# - Object detection
# - Label detection
# - Safe Search (content moderation)
# - Face detection
# - Landmark detection

# ============================================
# AI Cost Control Settings
# ============================================
# Maximum responses to analyze in a single survey batch (default: 500)
AI_MAX_BATCH_SIZE=500

# Enable/disable response caching (default: true)
AI_ENABLE_CACHING=true

# Cache TTL in milliseconds (default: 300000 = 5 minutes)
AI_CACHE_TTL=300000

# Maximum cache size (default: 500)
AI_MAX_CACHE_SIZE=500

# ============================================
# AI Rate Limiting
# ============================================
# Requests per minute for AI endpoints (default: 30)
AI_RATE_LIMIT_PER_MINUTE=30

# ============================================
# AI Feature-Specific Settings
# ============================================
# Automatically analyze sentiment for all performance reviews (default: true)
AI_AUTO_ANALYZE_PERFORMANCE=true

# Automatically analyze exit interviews when uploaded (default: true)
AI_AUTO_ANALYZE_EXIT_INTERVIEWS=true

# Minimum confidence level to show sentiment (high/medium/low)
AI_MIN_CONFIDENCE_LEVEL=low

# ============================================
# AI Monitoring & Logging
# ============================================
# Log all AI API calls for auditing (default: true)
AI_ENABLE_AUDIT_LOGGING=true

# Log cache statistics every N requests (default: 100, 0 to disable)
AI_LOG_CACHE_STATS_EVERY=100

# ============================================
# Google Cloud DLP (Data Loss Prevention)
# ============================================
# Documentation: See docs/guides/DLP_INTEGRATION_GUIDE.md
# Cost: FREE (stays within 1 GB/month free tier)

# Enable de-identification of employee data before sending to Claude API
# Pros: Maximum privacy, reduces risk if Claude API compromised
# Cons: May reduce Claude's accuracy for specific employee questions
# Default: false (recommended for most use cases)
NEXT_PUBLIC_DLP_DEIDENTIFY_CHAT=false

# DLP Features (always active when GOOGLE_APPLICATION_CREDENTIALS is set):
# - CSV uploads: Scans for PII, blocks critical uploads (SSN, credit cards)
# - Audit logs: Validates no PII in logs, auto-redacts if found
# - Chat (optional): De-identify employee data before Claude API

# ============================================
# Testing Commands
# ============================================
# Test Google Cloud AI setup:
# npx tsx tests/ai-integration/test-nlp-service.ts
# npx tsx tests/ai-integration/test-translation-service.ts
# npx tsx tests/ai-integration/test-speech-service.ts
# npx tsx tests/ai-integration/test-document-ai-service.ts
# npx tsx tests/ai-integration/test-vertex-ai-service.ts
#
# Test DLP setup:
# npx tsx tests/dlp-integration/test-dlp-setup.ts

# ============================================
# Production Notes
# ============================================
# For production deployment:
# 1. Use environment-specific secrets management (AWS Secrets Manager, etc.)
# 2. Change JWT_SECRET to a cryptographically secure random string
# 3. Set NODE_ENV=production
# 4. Enable monitoring (SENTRY_DSN, DATADOG_API_KEY)
# 5. Set NEXT_TELEMETRY_DISABLED=1
# 6. Configure ALLOWED_ORIGINS for your domain
# 7. See docs/guides/DEPLOYMENT_GUIDE.md for complete checklist
